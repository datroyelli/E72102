{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53fc7a33",
   "metadata": {},
   "source": [
    "# Ejemplo: Comparando modelos utilizando 5x2 cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e56467",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c43de90",
   "metadata": {},
   "source": [
    "Instalamos la librerias necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d3d6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/santiagxf/E72102/master/docs/develop/modeling/selection/code/5x2.txt \\\n",
    "    --quiet --no-clobber\n",
    "!pip install -r 5x2.txt --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8018f6fe",
   "metadata": {},
   "source": [
    "### Sobre el conjunto de datos del censo UCI\n",
    "\n",
    "El conjunto de datos del censo de la UCI es un conjunto de datos en el que cada registro representa a una persona. Cada registro contiene 14 columnas que describen a una una sola persona, de la base de datos del censo de Estados Unidos de 1994. Esto incluye información como la edad, el estado civil y el nivel educativo. La tarea es determinar si una persona tiene un ingreso alto (definido como ganar más de $50 mil al año). Esta tarea, dado el tipo de datos que utiliza, se usa a menudo en el estudio de equidad, en parte debido a los atributos comprensibles del conjunto de datos, incluidos algunos que contienen tipos sensibles como la edad y el género, y en parte también porque comprende una tarea claramente del mundo real."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34c4d95",
   "metadata": {},
   "source": [
    "Preparando nuestros conjuntos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fca1c236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('datasets/uci_census/data/adult-train.csv')\n",
    "\n",
    "train = df.drop(['income'], axis=1)\n",
    "target = df['income'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f404e3",
   "metadata": {},
   "source": [
    "## Preparación de los datos para el ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a21dd73",
   "metadata": {},
   "source": [
    "Realizaremos un pequeño preprocesamiento antes de entrenar el modelo:\n",
    "\n",
    "- Imputaremos los valores faltantes de las caracteristicas numéricas con la media\n",
    "- Imputaremos los valores faltantes de las caracteristicas categóricas con el valor `?`\n",
    "- Escalaremos los valores numericos utilizando un `StandardScaler`\n",
    "- Codificaremos las variables categóricas utilizando `OneHotEncoder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52c4bb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "def prepare(X: pd.DataFrame) -> Tuple[np.ndarray, sklearn.compose.ColumnTransformer]:\n",
    "    pipe_cfg = {\n",
    "        'num_cols': X.dtypes[X.dtypes == 'int64'].index.values.tolist(),\n",
    "        'cat_cols': X.dtypes[X.dtypes == 'object'].index.values.tolist(),\n",
    "    }\n",
    "    \n",
    "    num_pipe = Pipeline([\n",
    "        ('num_imputer', SimpleImputer(strategy='median')),\n",
    "        ('num_scaler', StandardScaler())\n",
    "    ])\n",
    "    \n",
    "    cat_pipe = Pipeline([\n",
    "        ('cat_imputer', SimpleImputer(strategy='constant', fill_value='?')),\n",
    "        ('cat_encoder', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "    ])\n",
    "    \n",
    "    transformations = ColumnTransformer([\n",
    "        ('num_pipe', num_pipe, pipe_cfg['num_cols']),\n",
    "        ('cat_pipe', cat_pipe, pipe_cfg['cat_cols'])\n",
    "    ])\n",
    "    X = transformations.fit_transform(X)\n",
    "    \n",
    "    return X, transformations\n",
    "\n",
    "\n",
    "train, transformations = prepare(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3f26a9",
   "metadata": {},
   "source": [
    "## Definiendo nuestros modelos a comparar\n",
    "\n",
    "Para demostrar la técnica, utilizaremos dos clasificadores basados en `LightGBM`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddc722a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "clf1 = LGBMClassifier(n_estimators=100, n_jobs=2)\n",
    "clf2 = LGBMClassifier(n_estimators=100, reg_alpha=1, reg_lambda=1, min_split_gain=2, n_jobs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fcb15c",
   "metadata": {},
   "source": [
    "## Procedimiento de 5x2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f3a98d",
   "metadata": {},
   "source": [
    "Generamos las semillas con las cuales generar los conjuntos de datos, los cuales son 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fb15057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seeds = [ random.randint(1,10000) for time in range(0,5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2866ca3f",
   "metadata": {},
   "source": [
    "Inicializamos arreglos para guardar los valores necesarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7973dc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.zeros((5,2)) # (numero de folds, numero de iteraciones)\n",
    "scores = np.zeros((2,5,2)) # (numero de modelos, numero de folds, numero de iteraciones)\n",
    "diff_scores = np.zeros((5,2)) # (numero de folds, numero de iteraciones)\n",
    "s_sqr = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c37ce31",
   "metadata": {},
   "source": [
    "El siguiente procedimiento calcula el valor estadístico que estamos necesitando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82b7a003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1 score difference = 0.002469\n",
      "Fold  2 score difference = 0.002163\n",
      "Fold  1 score difference = 0.001980\n",
      "Fold  2 score difference = 0.001963\n",
      "Fold  1 score difference = 0.001847\n",
      "Fold  2 score difference = 0.001401\n",
      "Fold  1 score difference = 0.001902\n",
      "Fold  2 score difference = 0.001199\n",
      "Fold  1 score difference = 0.002051\n",
      "Fold  2 score difference = 0.001228\n",
      "Performance del clasificador 1: 0.925682 +/- 0.001267\n",
      "Performance del clasificador 2 : 0.923862 +/- 0.001479\n",
      "Diferencia entre las performance: 0.001820 +/- 0.000395\n",
      "Valor estadístico de t: 6.450622\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "for i, seed in enumerate(seeds):\n",
    "    # Split the dataset in 2 parts with the current seed\n",
    "    folds = StratifiedKFold(n_splits=2, shuffle=True, random_state=seed)\n",
    "    \n",
    "    # Initialize score differences\n",
    "    for k, (trn_idx, val_idx) in enumerate(folds.split(target, target)):\n",
    "        # Split the data\n",
    "        trn_x, trn_y = train[trn_idx], target[trn_idx]\n",
    "        val_x, val_y = train[val_idx], target[val_idx]\n",
    "        \n",
    "        # Train classifiers\n",
    "        clf1.fit(trn_x, trn_y, eval_set=[(val_x, val_y)], early_stopping_rounds=20, verbose=0)\n",
    "        clf2.fit(trn_x, trn_y, eval_set=[(val_x, val_y)], early_stopping_rounds=20, verbose=0)\n",
    "        \n",
    "        # Compute scores\n",
    "        preds_1 = clf1.predict_proba(val_x, num_iteration=clf1.best_iteration_)[:, 1]\n",
    "        scores[0][i][k] = roc_auc_score(val_y, preds_1)\n",
    "        \n",
    "        preds_2 = clf2.predict_proba(val_x, num_iteration=clf2.best_iteration_)[:, 1]\n",
    "        scores[1][i][k] = roc_auc_score(val_y, preds_2)\n",
    "        \n",
    "        diff_scores[i][k] = scores[0][i][k] - scores[1][i][k]\n",
    "        print(\"Fold %2d score difference = %.6f\" % (k + 1, diff_scores[i][k]))\n",
    "        \n",
    "        # Compute score difference for current fold\n",
    "        p[i][k] = diff_scores[i][k]\n",
    "        \n",
    "\n",
    "    # Compute mean of scores difference for the current 2-fold CV\n",
    "    p_i_bar = (p[i][0] + p[i][1]) / 2\n",
    "    # Compute the variance estimate for the current 2-fold CV\n",
    "    s_sqr_i = (p[i][0] - p_i_bar) ** 2 + (p[i][1] - p_i_bar) ** 2 \n",
    "    # Add up to the overall variance\n",
    "    s_sqr += s_sqr_i\n",
    "    \n",
    "# Compute t value as the first difference divided by the square root of variance estimate\n",
    "t_bar = p[0][0] / ((s_sqr / 5) ** .5) \n",
    "\n",
    "print(\"Performance del clasificador 1: %.6f +/- %.6f\" % (np.mean(scores[0]), np.std(scores[0])))\n",
    "print(\"Performance del clasificador 2 : %.6f +/- %.6f\" % (np.mean(scores[1]), np.std(scores[1])))\n",
    "print(\"Diferencia entre las performance: %.6f +/- %.6f\" % (np.mean(diff_scores), np.std(diff_scores)))\n",
    "print(\"Valor estadístico de t: %.6f\" % t_bar )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6739a67",
   "metadata": {},
   "source": [
    "Computamos los valores críticos del intervalo de confianza para la distribución, significancia y grados de libertad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba1e1f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import t\n",
    "\n",
    "interval = t.interval(0.95, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9da26b8",
   "metadata": {},
   "source": [
    "Tomamos una decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33e5e09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existe suficiente evidencia para rechazar la idea de que los modelos son equivalentes en favor de           una alternativa de que los modelos son distintos.\n"
     ]
    }
   ],
   "source": [
    "if t_bar > interval[0] and t_bar < interval[1]:\n",
    "    print(\"No podemos tomar ninguna conclusión. No se puede rechazar la idea de que ambos modelos son equivalente\")\n",
    "else:\n",
    "    print(\"Existe suficiente evidencia para rechazar la idea de que los modelos son equivalentes en favor de \\\n",
    "          una alternativa de que los modelos son distintos.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
